#!/usr/bin/env python3
"""
SPR{K}3 Vulnerability Scanner v4.3
Security vulnerability detection for ML/AI codebases
Purpose: Defensive security tool to help developers find and fix vulnerabilities
License: Responsible use only - for security research and improvement
"""

import os
import sys
import re
import json
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple

class SPRk3VulnerabilityScanner:
    """
    Detects security vulnerabilities in ML/AI code to help developers
    write safer code and protect against attacks.
    """
    
    def __init__(self):
        self.vulnerabilities = []
        self.scan_count = 0
        
        # Detection patterns for known ML/AI vulnerabilities
        self.patterns = {
            'torch_unsafe': {
                'pattern': r'torch\.load\([^)]+\)',
                'check': self._check_torch_load,
                'severity': 'CRITICAL',
                'cwe': 'CWE-502',
                'description': 'Unsafe torch.load() - potential arbitrary code execution',
                'recommendation': 'Add weights_only=True parameter'
            },
            'pickle_unsafe': {
                'pattern': r'pickle\.load',
                'severity': 'CRITICAL',
                'cwe': 'CWE-502',
                'description': 'Unsafe pickle deserialization - arbitrary code execution risk',
                'recommendation': 'Use safer serialization formats (JSON, MessagePack)'
            },
            'eval_usage': {
                'pattern': r'\beval\s*\(',
                'severity': 'HIGH',
                'cwe': 'CWE-95',
                'description': 'eval() usage - code injection vulnerability',
                'recommendation': 'Use ast.literal_eval() or avoid eval entirely'
            },
            'exec_usage': {
                'pattern': r'\bexec\s*\(',
                'severity': 'HIGH',
                'cwe': 'CWE-95',
                'description': 'exec() usage - code injection vulnerability',
                'recommendation': 'Refactor to avoid dynamic code execution'
            },
            'yaml_unsafe': {
                'pattern': r'yaml\.load.*Loader\s*=\s*yaml\.(Loader|FullLoader|UnsafeLoader)',
                'severity': 'HIGH',
                'cwe': 'CWE-502',
                'description': 'Unsafe YAML loading - potential code execution',
                'recommendation': 'Use yaml.safe_load() or SafeLoader'
            },
            'joblib_load': {
                'pattern': r'joblib\.load',
                'severity': 'MEDIUM',
                'cwe': 'CWE-502',
                'description': 'joblib.load() may execute arbitrary code',
                'recommendation': 'Validate source and consider alternatives'
            },
            'dill_load': {
                'pattern': r'dill\.load',
                'severity': 'HIGH',
                'cwe': 'CWE-502',
                'description': 'dill.load() can execute arbitrary code',
                'recommendation': 'Use safer serialization methods'
            }
        }
    
    def _check_torch_load(self, match_text: str) -> bool:
        """Special check for torch.load - returns True if vulnerable"""
        return 'weights_only=True' not in match_text
    
    def scan_file(self, filepath: Path) -> List[Dict]:
        """Scan a single file for vulnerabilities"""
        self.scan_count += 1
        
        try:
            with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
                lines = content.split('\n')
        except Exception as e:
            return []
        
        file_vulns = []
        
        for vuln_type, config in self.patterns.items():
            pattern = config['pattern']
            
            for match in re.finditer(pattern, content):
                # Special handling for patterns with custom checks
                if 'check' in config:
                    if not config['check'](match.group()):
                        continue
                
                line_num = content[:match.start()].count('\n') + 1
                
                vuln = {
                    'file': str(filepath),
                    'line': line_num,
                    'type': vuln_type,
                    'severity': config['severity'],
                    'cwe': config.get('cwe', 'N/A'),
                    'description': config['description'],
                    'recommendation': config.get('recommendation', ''),
                    'code_snippet': lines[line_num-1].strip()[:100] if line_num <= len(lines) else ''
                }
                
                file_vulns.append(vuln)
        
        return file_vulns
    
    def scan_directory(self, directory: str, exclude_tests: bool = False) -> List[Dict]:
        """Scan all Python files in directory"""
        path = Path(directory)
        
        if not path.exists():
            print(f"Error: Path {directory} does not exist")
            return []
        
        # Find all Python files
        py_files = list(path.rglob('*.py'))
        
        # Optionally exclude test files
        if exclude_tests:
            py_files = [f for f in py_files if '/test' not in str(f) and '/tests' not in str(f)]
        
        print(f"\n[*] Scanning {len(py_files)} Python files...")
        print(f"[*] Exclude tests: {exclude_tests}")
        
        for i, py_file in enumerate(py_files, 1):
            # Progress indicator
            if i % 100 == 0 or i == len(py_files):
                print(f"    Progress: {i}/{len(py_files)} files...")
            
            vulns = self.scan_file(py_file)
            self.vulnerabilities.extend(vulns)
        
        return self.vulnerabilities
    
    def generate_report(self, output_format: str = 'both'):
        """Generate vulnerability report"""
        if not self.vulnerabilities:
            print("\n‚úÖ No vulnerabilities found!")
            return
        
        # Group by severity
        severity_groups = {}
        for vuln in self.vulnerabilities:
            sev = vuln['severity']
            if sev not in severity_groups:
                severity_groups[sev] = []
            severity_groups[sev].append(vuln)
        
        # Console output
        print("\n" + "="*60)
        print("SPR{K}3 VULNERABILITY SCAN REPORT")
        print("="*60)
        print(f"\nüìä Summary:")
        print(f"   Files scanned: {self.scan_count}")
        print(f"   Total vulnerabilities: {len(self.vulnerabilities)}")
        
        for severity in ['CRITICAL', 'HIGH', 'MEDIUM', 'LOW']:
            if severity in severity_groups:
                print(f"   {severity}: {len(severity_groups[severity])}")
        
        # Show sample vulnerabilities
        for severity in ['CRITICAL', 'HIGH']:
            if severity in severity_groups:
                print(f"\n{'üö®' if severity == 'CRITICAL' else '‚ö†Ô∏è'} {severity} Vulnerabilities (first 5):")
                for vuln in severity_groups[severity][:5]:
                    rel_path = vuln['file'].replace(os.path.expanduser('~'), '~')
                    print(f"   {rel_path}:{vuln['line']}")
                    print(f"      {vuln['description']}")
                    print(f"      Fix: {vuln['recommendation']}")
        
        # Save JSON report
        if output_format in ['json', 'both']:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            report_file = f"sprk3_scan_{timestamp}.json"
            
            report_data = {
                'scan_metadata': {
                    'scanner_version': 'SPR{K}3 v4.3',
                    'scan_date': datetime.now().isoformat(),
                    'files_scanned': self.scan_count,
                    'total_vulnerabilities': len(self.vulnerabilities)
                },
                'summary': {sev: len(vulns) for sev, vulns in severity_groups.items()},
                'vulnerabilities': self.vulnerabilities[:1000]  # Limit to prevent huge files
            }
            
            with open(report_file, 'w') as f:
                json.dump(report_data, f, indent=2)
            
            print(f"\nüìÅ Detailed report saved to: {report_file}")

def main():
    """Main entry point"""
    import argparse
    
    print("\n" + "="*60)
    print("  SPR{K}3 Vulnerability Scanner v4.3")
    print("  Defensive Security Tool for ML/AI Code")
    print("  Purpose: Help developers find and fix vulnerabilities")
    print("="*60)
    
    parser = argparse.ArgumentParser(description='Scan ML/AI code for security vulnerabilities')
    parser.add_argument('path', help='Directory or file to scan')
    parser.add_argument('--exclude-tests', action='store_true', help='Exclude test directories')
    parser.add_argument('--format', choices=['console', 'json', 'both'], default='both',
                       help='Output format (default: both)')
    
    args = parser.parse_args()
    
    scanner = SPRk3VulnerabilityScanner()
    
    if os.path.isfile(args.path):
        vulns = scanner.scan_file(Path(args.path))
        scanner.vulnerabilities = vulns
    else:
        scanner.scan_directory(args.path, exclude_tests=args.exclude_tests)
    
    scanner.generate_report(output_format=args.format)
    
    # Exit code based on findings
    if scanner.vulnerabilities:
        severity_list = [v['severity'] for v in scanner.vulnerabilities]
        if 'CRITICAL' in severity_list:
            sys.exit(2)  # Critical vulnerabilities found
        elif 'HIGH' in severity_list:
            sys.exit(1)  # High vulnerabilities found
    
    sys.exit(0)  # Clean

if __name__ == "__main__":
    main()
