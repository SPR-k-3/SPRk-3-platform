#!/usr/bin/env python3
"""
SPR{K}3 Vulnerability Scanner v4.1
Combines all detection engines for comprehensive security analysis
"""

import os
import sys
import re
import json
from pathlib import Path
from datetime import datetime

class VulnerabilityScanner:
    def __init__(self):
        self.vulnerabilities = []
        self.patterns = {
            'torch_unsafe': {
                'pattern': r'torch\.load\([^)]+\)',
                'check': lambda x: 'weights_only=True' not in x,
                'severity': 'CRITICAL',
                'description': 'Unsafe torch.load() without weights_only=True - arbitrary code execution'
            },
            'pickle_unsafe': {
                'pattern': r'pickle\.load',
                'severity': 'CRITICAL',
                'description': 'Unsafe pickle.load() - arbitrary code execution risk'
            },
            'eval_usage': {
                'pattern': r'\beval\s*\(',
                'severity': 'HIGH',
                'description': 'eval() usage - code injection risk'
            },
            'exec_usage': {
                'pattern': r'\bexec\s*\(',
                'severity': 'HIGH',
                'description': 'exec() usage - code injection risk'
            },
            'yaml_unsafe': {
                'pattern': r'yaml\.load\s*\([^)]*Loader\s*=\s*yaml\.Loader',
                'severity': 'HIGH',
                'description': 'Unsafe yaml.load() with yaml.Loader'
            }
        }
    
    def scan_file(self, filepath):
        """Scan a single file for vulnerabilities"""
        try:
            with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
                lines = content.split('\n')
        except:
            return []
        
        file_vulns = []
        
        for vuln_type, config in self.patterns.items():
            pattern = config['pattern']
            matches = list(re.finditer(pattern, content))
            
            for match in matches:
                # Special handling for torch.load
                if vuln_type == 'torch_unsafe':
                    if 'weights_only=True' in match.group():
                        continue
                
                # Find line number
                line_num = content[:match.start()].count('\n') + 1
                
                file_vulns.append({
                    'file': str(filepath),
                    'line': line_num,
                    'type': vuln_type,
                    'severity': config['severity'],
                    'description': config['description'],
                    'code': lines[line_num-1].strip() if line_num <= len(lines) else ''
                })
        
        return file_vulns
    
    def scan_directory(self, directory):
        """Scan all Python files in directory"""
        path = Path(directory)
        py_files = list(path.rglob('*.py'))
        
        print(f"\n[*] Scanning {len(py_files)} Python files in {directory}")
        
        for py_file in py_files:
            vulns = self.scan_file(py_file)
            self.vulnerabilities.extend(vulns)
        
        return self.vulnerabilities
    
    def generate_report(self):
        """Generate formatted report"""
        if not self.vulnerabilities:
            print("\nâœ… No vulnerabilities found!")
            return
        
        print("\n" + "="*60)
        print("SPR{K}3 VULNERABILITY REPORT")
        print("="*60)
        
        # Group by severity
        critical = [v for v in self.vulnerabilities if v['severity'] == 'CRITICAL']
        high = [v for v in self.vulnerabilities if v['severity'] == 'HIGH']
        medium = [v for v in self.vulnerabilities if v['severity'] == 'MEDIUM']
        
        print(f"\nðŸ“Š Summary:")
        print(f"   CRITICAL: {len(critical)}")
        print(f"   HIGH: {len(high)}")
        print(f"   MEDIUM: {len(medium)}")
        print(f"   TOTAL: {len(self.vulnerabilities)}")
        
        if critical:
            print(f"\nðŸš¨ CRITICAL Vulnerabilities:")
            for vuln in critical:
                print(f"   [{vuln['severity']}] {vuln['description']}")
                print(f"          File: {vuln['file']}:{vuln['line']}")
                print(f"          Code: {vuln['code'][:60]}...")
        
        if high:
            print(f"\nâš ï¸  HIGH Vulnerabilities:")
            for vuln in high:
                print(f"   [{vuln['severity']}] {vuln['description']}")
                print(f"          File: {vuln['file']}:{vuln['line']}")
                print(f"          Code: {vuln['code'][:60]}...")
        
        # Save JSON report
        report_file = f"sprk3_scan_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_file, 'w') as f:
            json.dump({
                'scan_date': datetime.now().isoformat(),
                'vulnerabilities': self.vulnerabilities,
                'summary': {
                    'critical': len(critical),
                    'high': len(high),
                    'medium': len(medium),
                    'total': len(self.vulnerabilities)
                }
            }, f, indent=2)
        
        print(f"\nðŸ“ Full report saved to: {report_file}")

def main():
    if len(sys.argv) < 2:
        print("Usage: python3 sprk3_vulnerability_scanner.py <directory>")
        sys.exit(1)
    
    target = sys.argv[1]
    
    print("\n" + "="*60)
    print("  SPR{K}3 Vulnerability Scanner v4.1")
    print("  Supply Chain & ML Security Analysis")
    print("="*60)
    
    scanner = VulnerabilityScanner()
    scanner.scan_directory(target)
    scanner.generate_report()

if __name__ == "__main__":
    main()

# Add these patterns to the scanner's __init__ method:
# (You'll need to edit the file to add these to the patterns dictionary)

'yaml_unsafe': {
    'pattern': r'yaml\.load.*Loader\s*=\s*yaml\.(Loader|FullLoader)',
    'severity': 'HIGH',
    'description': 'Unsafe yaml.load() with unsafe Loader - code execution risk'
},
'dill_unsafe': {
    'pattern': r'dill\.load',
    'severity': 'CRITICAL', 
    'description': 'Unsafe dill.load() - arbitrary code execution risk'
},
'joblib_unsafe': {
    'pattern': r'joblib\.load',
    'severity': 'HIGH',
    'description': 'Unsafe joblib.load() - potential code execution'
}
