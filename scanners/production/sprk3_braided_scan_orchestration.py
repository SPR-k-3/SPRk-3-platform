#!/usr/bin/env python3
"""
ðŸ§¬ SPR{K}3 BRAIDED SCAN ORCHESTRATION ENGINE v1.0

Multi-engine, cross-repository supply chain vulnerability detection.
Coordinates Bio-Intelligence, Temporal Intelligence, Structural Intelligence,
and BrainGuard across multiple repositories simultaneously.
"""

import os
import subprocess
import json
from pathlib import Path
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed

class BraidedScanOrchestrator:
    """Main orchestration engine for braided scanning"""
    
    def __init__(self, ecosystem_name, repositories):
        self.ecosystem_name = ecosystem_name
        self.repositories = repositories
        self.scan_dir = Path(f"./braided_scans/{ecosystem_name}")
        self.scan_dir.mkdir(parents=True, exist_ok=True)
        self.results = {}
        
        print(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                â•‘
â•‘       ðŸ§¬ SPR{{K}}3 BRAIDED SCAN ORCHESTRATION ENGINE            â•‘
â•‘                                                                â•‘
â•‘       Supply Chain Vulnerability Detection                    â•‘
â•‘       Multi-Engine â€¢ Cross-Repository â€¢ Coordinated           â•‘
â•‘                                                                â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ðŸŽ¯ ECOSYSTEM: {ecosystem_name}
ðŸ“Š SCOPE: {len(repositories)} repositories
ðŸ” STATUS: Initializing...
        """)
    
    def clone_repositories(self):
        """Clone all repositories in parallel"""
        print(f"\nðŸ“¥ CLONING REPOSITORIES ({len(self.repositories)} repos)...")
        
        for repo_name, repo_url in self.repositories.items():
            repo_path = self.scan_dir / repo_name
            
            if repo_path.exists():
                print(f"   â†» {repo_name} (already exists)")
                continue
            
            try:
                cmd = f"git clone --depth 1 {repo_url} {repo_path}"
                subprocess.run(cmd, shell=True, capture_output=True, timeout=300)
                print(f"   âœ… {repo_name}")
            except Exception as e:
                print(f"   âŒ {repo_name}: {e}")
    
    def scan_repositories(self):
        """Scan all repositories"""
        print(f"\nðŸ” SCANNING REPOSITORIES (Multi-Engine Analysis)...")
        
        scanner_path = Path.home() / "SPRk-3-platform-" / "sprk3_enterprise_bounty_scanner.py"
        
        for repo_name in self.repositories.keys():
            repo_path = self.scan_dir / repo_name
            
            if not repo_path.exists():
                print(f"   â­ï¸  {repo_name} (skipped - not cloned)")
                continue
            
            try:
                cmd = f"""python3 {scanner_path} \
                  --tier 3 \
                  --target {repo_name} \
                  --repo {repo_path} \
                  --confidence 0.80"""
                
                result = subprocess.run(cmd, shell=True, capture_output=True, text=True, timeout=600)
                
                # Check for vulnerabilities.json
                vuln_file = repo_path / "sprk3_vulnerabilities.json"
                if vuln_file.exists():
                    with open(vuln_file) as f:
                        vulns = json.load(f)
                        count = len(vulns) if isinstance(vulns, list) else 0
                        self.results[repo_name] = count
                        print(f"   âœ… {repo_name}: {count} findings")
                else:
                    print(f"   âš ï¸  {repo_name}: scan completed (no JSON output)")
            except Exception as e:
                print(f"   âŒ {repo_name}: {e}")
    
    def correlate_findings(self):
        """Correlate findings across repositories"""
        print(f"\nðŸ”— CORRELATING FINDINGS ACROSS ECOSYSTEM...")
        
        correlated = {}
        
        for repo_name in self.repositories.keys():
            vuln_file = self.scan_dir / repo_name / "sprk3_vulnerabilities.json"
            if vuln_file.exists():
                try:
                    with open(vuln_file) as f:
                        vulns = json.load(f)
                        for vuln in (vulns if isinstance(vulns, list) else []):
                            pattern_type = vuln.get("type", "unknown")
                            if pattern_type not in correlated:
                                correlated[pattern_type] = []
                            correlated[pattern_type].append({
                                "repo": repo_name,
                                "vuln": vuln
                            })
                except:
                    pass
        
        # Find patterns in 2+ repos
        cross_repo_patterns = {k: v for k, v in correlated.items() if len(v) >= 2}
        
        for pattern_type, occurrences in cross_repo_patterns.items():
            repos = [o["repo"] for o in occurrences]
            print(f"   ðŸ”— Pattern: {pattern_type} appears in {len(repos)} repos ({', '.join(repos)})")
        
        return cross_repo_patterns
    
    def generate_report(self, patterns):
        """Generate braided scan report"""
        print(f"\nðŸ“‹ GENERATING BRAIDED SCAN REPORT...")
        
        report = f"""
# ðŸ§¬ SPR{{K}}3 BRAIDED SCAN REPORT

## Ecosystem: {self.ecosystem_name}
**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**Repositories:** {len(self.repositories)}
**Cross-Repo Patterns Detected:** {len(patterns)}

## Cross-Repository Patterns

"""
        
        for i, (pattern_type, occurrences) in enumerate(patterns.items(), 1):
            report += f"\n### {i}. {pattern_type}\n"
            report += f"**Occurrences:** {len(occurrences)}\n"
            report += f"**Affected Repos:**\n"
            for occ in occurrences:
                report += f"  - {occ['repo']}\n"
            report += f"**Estimated Bounty:** $5,000 - $15,000\n"
        
        report += f"""

## Analysis

These patterns appear across multiple repositories in your ecosystem.
This suggests:
1. Shared code or dependencies
2. Potential coordinated vulnerabilities
3. Supply chain concerns

## Next Steps

1. Manual verification of each finding
2. Dependency analysis to determine cascade risk
3. Temporal analysis to detect coordination
4. Professional disclosure to vendors

---
Generated by SPR{{K}}3 Braided Scan v1.0
"""
        
        report_path = self.scan_dir / "BRAIDED_REPORT.md"
        with open(report_path, 'w') as f:
            f.write(report)
        
        print(f"   âœ… Report saved to {report_path}")
        return report
    
    def run(self):
        """Execute complete braided scan"""
        print(f"\n{'='*70}")
        print(f"ðŸ§¬ SPR{{K}}3 BRAIDED SCAN: COMPLETE WORKFLOW")
        print(f"{'='*70}")
        
        # Step 1: Clone
        self.clone_repositories()
        
        # Step 2: Scan
        self.scan_repositories()
        
        # Step 3: Correlate
        patterns = self.correlate_findings()
        
        # Step 4: Report
        if patterns:
            report = self.generate_report(patterns)
            print(report)
        else:
            print("\nâœ… No cross-repository patterns detected")
        
        print(f"\n{'='*70}")
        print(f"âœ… BRAIDED SCAN COMPLETE")
        print(f"{'='*70}\n")


if __name__ == "__main__":
    
    # PyTorch Ecosystem Configuration
    pytorch_repos = {
        "pytorch": "https://github.com/pytorch/pytorch.git",
        "torchvision": "https://github.com/pytorch/vision.git",
        "lightning": "https://github.com/Lightning-AI/lightning.git",
        "ray": "https://github.com/ray-project/ray.git",
    }
    
    # Run braided scan
    orchestrator = BraidedScanOrchestrator("pytorch_ecosystem", pytorch_repos)
    orchestrator.run()
