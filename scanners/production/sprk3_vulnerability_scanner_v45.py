#!/usr/bin/env python3
"""
SPR{K}3 Vulnerability Scanner v4.5 - Platform Edition
Enterprise-grade ML/AI security scanner with notebook support, taint analysis, and smart filtering
Purpose: Defensive security tool to help developers find and fix vulnerabilities
License: Responsible use only - for security research and improvement
"""

import os
import sys
import re
import json
import glob
import fnmatch
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional, Set, Tuple
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading

class SPRk3VulnerabilityScanner:
    """
    Platform-grade security vulnerability detection for ML/AI codebases
    v4.5: Notebook support, taint analysis, include/exclude globs, inline fixes
    """
    
    def __init__(self):
        self.vulnerabilities = []
        self.scan_count = 0
        self.flags = re.IGNORECASE | re.MULTILINE | re.DOTALL
        self.compiled = {}
        self.lock = threading.Lock()
        
        # Taint sources that increase severity
        self.taint_sources = [
            'request', 'user', 'input', 'args', 'argv', 'environ',
            'getenv', 'POST', 'GET', 'params', 'query', 'form',
            'cookie', 'session', 'flask.request', 'django.request'
        ]
        
        # Default excludes for performance
        self.default_excludes = [
            '**/site-packages/**', '**/node_modules/**', '**/venv/**',
            '**/env/**', '**/.env/**', '**/dist/**', '**/build/**',
            '**/data/**', '**/datasets/**', '**/__pycache__/**',
            '**/.git/**', '**/migrations/**'
        ]
        
        # 30+ vulnerability patterns across 11 categories
        self.patterns = {
            # ========== DESERIALIZATION (8 patterns) ==========
            'torch_unsafe': {
                'pattern': r'torch\.load\s*\((?P<args>.*?)\)',
                'check': self._check_torch_load,
                'severity': 'CRITICAL',
                'cwe': 'CWE-502',
                'description': 'Unsafe torch.load() - arbitrary code execution',
                'recommendation': 'Add weights_only=True parameter',
                'fix_hint': 'torch.load(path, weights_only=True)'
            },
            'pickle_unsafe': {
                'pattern': r'pickle\.(load|loads)\s*\(',
                'severity': 'CRITICAL',
                'cwe': 'CWE-502',
                'description': 'Unsafe pickle deserialization',
                'recommendation': 'Use safer formats (JSON, MessagePack)',
                'fix_hint': 'json.load() or msgpack.unpack()'
            },
            'dill_load': {
                'pattern': r'dill\.(load|loads)\s*\(',
                'severity': 'HIGH',
                'cwe': 'CWE-502',
                'description': 'dill can execute arbitrary code',
                'recommendation': 'Use safer serialization',
                'fix_hint': 'Consider JSON or protocol buffers'
            },
            'joblib_load': {
                'pattern': r'joblib\.load\s*\(',
                'severity': 'HIGH',
                'cwe': 'CWE-502',
                'description': 'joblib uses pickle internally',
                'recommendation': 'Verify source trustworthiness',
                'fix_hint': 'Load only from trusted sources'
            },
            'numpy_load': {
                'pattern': r'numpy\.load\s*\([^)]*allow_pickle\s*=\s*True',
                'severity': 'HIGH',
                'cwe': 'CWE-502',
                'description': 'NumPy with pickle enabled',
                'recommendation': 'Set allow_pickle=False',
                'fix_hint': 'np.load(file, allow_pickle=False)'
            },
            'pandas_read_pickle': {
                'pattern': r'(?:pd|pandas)\.read_pickle',
                'severity': 'HIGH',
                'cwe': 'CWE-502',
                'description': 'Pandas pickle can execute code',
                'recommendation': 'Use parquet or feather format',
                'fix_hint': 'pd.read_parquet() or pd.read_feather()'
            },
            'yaml_unsafe': {
                'pattern': r'yaml\.load\s*\((?P<yargs>.*?)\)',
                'check': self._check_yaml_load,
                'severity': 'HIGH',
                'cwe': 'CWE-502',
                'description': 'Potentially unsafe YAML loading',
                'recommendation': 'Use yaml.safe_load()',
                'fix_hint': 'yaml.safe_load(data)'
            },
            'cloudpickle_load': {
                'pattern': r'cloudpickle\.(load|loads)\s*\(',
                'severity': 'HIGH',
                'cwe': 'CWE-502',
                'description': 'CloudPickle can execute arbitrary code',
                'recommendation': 'Use trusted sources only',
                'fix_hint': 'Verify source before loading'
            },
            
            # ========== MODEL LOADING (4 patterns) ==========
            'tensorflow_load_unsafe': {
                'pattern': r'tf\.keras\.models\.load_model\s*\([^)]*\)',
                'check': self._check_tf_load,
                'severity': 'HIGH',
                'cwe': 'CWE-502',
                'description': 'TensorFlow model may execute Lambda layers',
                'recommendation': 'Set custom_objects=None',
                'fix_hint': 'load_model(path, custom_objects=None)'
            },
            'onnx_load': {
                'pattern': r'onnx\.load(?:_model)?\s*\(',
                'severity': 'MEDIUM',
                'cwe': 'CWE-502',
                'description': 'ONNX model should be validated',
                'recommendation': 'Use onnx.checker.check_model()',
                'fix_hint': 'model = onnx.load(f); onnx.checker.check_model(model)'
            },
            'transformers_unsafe': {
                'pattern': r'from_pretrained\s*\((?P<args>(?:(?!\)).)*)\)',
                'check': self._check_hf_model,
                'severity': 'HIGH',
                'cwe': 'CWE-502',
                'description': 'HuggingFace model security risk',
                'recommendation': 'Pin revision and verify trust_remote_code',
                'fix_hint': "from_pretrained('model', revision='SHA', trust_remote_code=False)"
            },
            'model_from_url': {
                'pattern': r'(?:torch|tf|keras)\..*load.*https?://',
                'severity': 'HIGH',
                'cwe': 'CWE-494',
                'description': 'Loading model from URL without verification',
                'recommendation': 'Verify checksum/signature',
                'fix_hint': 'Download, verify hash, then load locally'
            },
            
            # ========== CODE INJECTION (2 patterns) ==========
            'eval_usage': {
                'pattern': r'\beval\s*\(',
                'severity': 'HIGH',
                'cwe': 'CWE-95',
                'description': 'eval() allows code injection',
                'recommendation': 'Use ast.literal_eval()',
                'fix_hint': 'ast.literal_eval(expression)'
            },
            'exec_usage': {
                'pattern': r'\bexec\s*\(',
                'severity': 'HIGH',
                'cwe': 'CWE-95',
                'description': 'exec() allows code injection',
                'recommendation': 'Refactor to avoid dynamic execution',
                'fix_hint': 'Use function calls instead of exec'
            },
            
            # ========== COMMAND INJECTION (3 patterns) ==========
            'subprocess_shell': {
                'pattern': r'subprocess\.\w+\s*\([^)]*shell\s*=\s*True',
                'severity': 'CRITICAL',
                'cwe': 'CWE-78',
                'description': 'Command injection via shell=True',
                'recommendation': 'Use shell=False with list args',
                'fix_hint': 'subprocess.run(["cmd", "arg"], shell=False)'
            },
            'os_system': {
                'pattern': r'os\.system\s*\(',
                'severity': 'HIGH',
                'cwe': 'CWE-78',
                'description': 'os.system() allows command injection',
                'recommendation': 'Use subprocess.run()',
                'fix_hint': 'subprocess.run(["cmd", "arg"], check=True)'
            },
            'os_popen': {
                'pattern': r'os\.popen\s*\(',
                'severity': 'HIGH',
                'cwe': 'CWE-78',
                'description': 'os.popen() allows command injection',
                'recommendation': 'Use subprocess.Popen()',
                'fix_hint': 'subprocess.Popen(["cmd"], stdout=subprocess.PIPE)'
            },
            
            # ========== SQL INJECTION (2 patterns) ==========
            'sql_format': {
                'pattern': r'(?:SELECT|INSERT|UPDATE|DELETE).*?(?:%s|%d|\.format\()',
                'severity': 'HIGH',
                'cwe': 'CWE-89',
                'description': 'SQL injection via string formatting',
                'recommendation': 'Use parameterized queries',
                'fix_hint': 'cursor.execute("SELECT * WHERE id=?", (user_id,))'
            },
            'sql_f_string': {
                'pattern': r'f["\'].*?\b(?:SELECT|INSERT|UPDATE|DELETE)\b',
                'severity': 'HIGH',
                'cwe': 'CWE-89',
                'description': 'SQL injection via f-strings',
                'recommendation': 'Use parameterized queries',
                'fix_hint': 'Use ? or %s placeholders with parameters'
            },
            
            # ========== SECRETS (3 patterns) ==========
            'hardcoded_secret': {
                'pattern': r'(?:password|passwd|pwd|secret|api_key|apikey|token)\s*=\s*["\'][^"\']{8,}["\']',
                'severity': 'HIGH',
                'cwe': 'CWE-798',
                'description': 'Hardcoded credential detected',
                'recommendation': 'Use environment variables',
                'fix_hint': 'os.getenv("API_KEY")'
            },
            'aws_credentials': {
                'pattern': r'(?:AKIA[0-9A-Z]{16}|aws_secret_access_key\s*=\s*["\'][A-Za-z0-9/+=]{35,})',
                'severity': 'CRITICAL',
                'cwe': 'CWE-798',
                'description': 'AWS credentials exposed',
                'recommendation': 'Use IAM roles',
                'fix_hint': 'Use boto3.Session() with IAM role'
            },
            'private_key': {
                'pattern': r'-----BEGIN (?:RSA |EC )?PRIVATE KEY-----',
                'severity': 'CRITICAL',
                'cwe': 'CWE-798',
                'description': 'Private key in code',
                'recommendation': 'Store in secure vault',
                'fix_hint': 'Load from environment or secret manager'
            },
            
            # ========== NETWORK SECURITY (2 patterns) ==========
            'ssl_verify_false': {
                'pattern': r'verify\s*=\s*False|ssl\.CERT_NONE',
                'severity': 'MEDIUM',
                'cwe': 'CWE-295',
                'description': 'SSL verification disabled',
                'recommendation': 'Enable certificate verification',
                'fix_hint': 'requests.get(url, verify=True)'
            },
            'http_without_tls': {
                'pattern': r'http://[^"\s]+(?:api|auth|login|secret|key|token)',
                'severity': 'MEDIUM',
                'cwe': 'CWE-319',
                'description': 'Sensitive data over HTTP',
                'recommendation': 'Use HTTPS',
                'fix_hint': 'Use https:// for sensitive endpoints'
            },
            
            # ========== Additional patterns ==========
            'md5_usage': {
                'pattern': r'hashlib\.md5\s*\(',
                'severity': 'MEDIUM',
                'cwe': 'CWE-328',
                'description': 'MD5 is cryptographically broken',
                'recommendation': 'Use SHA-256',
                'fix_hint': 'hashlib.sha256()'
            },
            'tempfile_mktemp': {
                'pattern': r'tempfile\.mktemp\s*\(',
                'severity': 'MEDIUM',
                'cwe': 'CWE-377',
                'description': 'mktemp() has race conditions',
                'recommendation': 'Use mkstemp()',
                'fix_hint': 'tempfile.mkstemp()'
            },
            'random_seed_fixed': {
                'pattern': r'random\.seed\s*\(\s*\d+\s*\)',
                'severity': 'LOW',
                'cwe': 'CWE-338',
                'description': 'Fixed random seed',
                'recommendation': 'Remove in production',
                'fix_hint': 'Remove or use random.seed()'
            },
            'assert_used': {
                'pattern': r'\bassert\s+',
                'severity': 'LOW',
                'cwe': 'CWE-617',
                'description': 'Assert can be disabled',
                'recommendation': 'Use explicit checks',
                'fix_hint': 'if not condition: raise ValueError()'
            }
        }
    
    def _check_torch_load(self, match_text: str) -> Optional[str]:
        """Check torch.load with taint analysis"""
        args = match_text
        
        # Check for weights_only parameter
        if 'weights_only' not in args:
            severity = 'CRITICAL'
        elif re.search(r'weights_only\s*=\s*False\b', args, re.IGNORECASE):
            severity = 'CRITICAL'
        elif re.search(r'weights_only\s*=\s*True\b', args, re.IGNORECASE):
            return None  # Safe
        else:
            severity = 'HIGH'  # Variable/expression
        
        # Apply taint analysis
        if self._has_taint(args):
            return 'CRITICAL' if severity == 'HIGH' else severity
        elif self._is_literal(args):
            return 'MEDIUM' if severity == 'CRITICAL' else 'LOW'
        
        return severity
    
    def _check_yaml_load(self, match_text: str) -> Optional[str]:
        """Check YAML loading with enhanced detection"""
        if re.search(r'Loader\s*=\s*yaml\.UnsafeLoader', match_text):
            return 'HIGH' if not self._has_taint(match_text) else 'CRITICAL'
        if re.search(r'Loader\s*=\s*yaml\.SafeLoader', match_text):
            return None
        if re.search(r'Loader\s*=\s*yaml\.FullLoader', match_text):
            return 'MEDIUM'
        # No loader = unsafe in old PyYAML
        return 'HIGH'
    
    def _check_tf_load(self, match_text: str) -> Optional[str]:
        """Check TensorFlow model loading"""
        if 'custom_objects=None' in match_text:
            return None
        if 'custom_objects' in match_text:
            return 'MEDIUM'
        return 'HIGH'
    
    def _check_hf_model(self, match_text: str) -> Optional[str]:
        """Check HuggingFace model loading for security issues"""
        severity = None
        
        # Check trust_remote_code
        if 'trust_remote_code=True' in match_text:
            severity = 'HIGH'
        
        # Check for unpinned revision
        if 'revision=' not in match_text or 'revision="main"' in match_text:
            if severity:
                return 'CRITICAL'  # Both issues
            severity = 'MEDIUM'
        
        # URL without verification
        if re.search(r'https?://', match_text) and 'verify' not in match_text:
            return 'HIGH'
        
        return severity
    
    def _has_taint(self, text: str) -> bool:
        """Check if text contains tainted sources"""
        text_lower = text.lower()
        return any(source in text_lower for source in self.taint_sources)
    
    def _is_literal(self, text: str) -> bool:
        """Check if arguments appear to be literals"""
        # Simple heuristic: only strings, numbers, True/False
        clean = re.sub(r'["\'\s\d\.,\(\)]+', '', text)
        clean = re.sub(r'\b(True|False|None)\b', '', clean)
        return len(clean) < 10
    
    def _load_baseline(self, path: Optional[str]) -> Set:
        """Load baseline suppressions"""
        if not path:
            return set()
        try:
            with open(path, 'r') as f:
                data = json.load(f)
            return {(d["file"], int(d["line"]), d["type"]) for d in data}
        except Exception:
            return set()
    
    def _parse_notebook(self, filepath: Path) -> str:
        """Extract code from Jupyter notebook"""
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                notebook = json.load(f)
            
            code_cells = []
            for cell in notebook.get('cells', []):
                if cell.get('cell_type') == 'code':
                    source = cell.get('source', [])
                    if isinstance(source, list):
                        code_cells.append(''.join(source))
                    else:
                        code_cells.append(source)
            
            return '\n'.join(code_cells)
        except Exception:
            return ''
    
    def scan_file(self, filepath: Path) -> List[Dict]:
        """Scan a single file (Python or notebook)"""
        self.scan_count += 1
        
        # Skip huge files
        try:
            if filepath.stat().st_size > 2_000_000:  # 2MB
                return []
        except:
            pass
        
        # Handle notebooks
        if str(filepath).endswith('.ipynb'):
            content = self._parse_notebook(filepath)
            if not content:
                return []
            lines = content.split('\n')
        else:
            try:
                with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read()
                    lines = content.split('\n')
            except Exception:
                return []
        
        # Compile patterns on first use
        if not self.compiled:
            for k, cfg in self.patterns.items():
                self.compiled[k] = re.compile(cfg['pattern'], self.flags)
        
        file_vulns = []
        
        for vuln_type, config in self.patterns.items():
            cre = self.compiled[vuln_type]
            
            for match in cre.finditer(content):
                sev_override = None
                if 'check' in config:
                    sev_override = config['check'](match.group())
                    if sev_override is False or sev_override is None:
                        continue
                
                line_num = content[:match.start()].count('\n') + 1
                
                # Skip comments
                if line_num <= len(lines):
                    line = lines[line_num - 1]
                    if line.strip().startswith('#'):
                        continue
                
                vuln = {
                    'file': str(filepath),
                    'line': line_num,
                    'type': vuln_type,
                    'severity': sev_override if isinstance(sev_override, str) else config['severity'],
                    'cwe': config.get('cwe', 'N/A'),
                    'description': config['description'],
                    'recommendation': config.get('recommendation', ''),
                    'fix_hint': config.get('fix_hint', ''),
                    'code_snippet': lines[line_num-1].strip()[:100] if line_num <= len(lines) else ''
                }
                
                file_vulns.append(vuln)
        
        return file_vulns
    
    def scan_directory(self, directory: str, include_patterns: List[str] = None,
                       exclude_patterns: List[str] = None, max_files: Optional[int] = None) -> List[Dict]:
        """Scan directory with include/exclude patterns and threading"""
        path = Path(directory)
        
        if not path.exists():
            print(f"Error: Path {directory} does not exist")
            return []
        
        # Find Python and notebook files
        all_files = list(path.rglob('*.py')) + list(path.rglob('*.ipynb'))
        
        # Apply include patterns
        if include_patterns:
            included = []
            for pattern in include_patterns:
                for file in all_files:
                    if fnmatch.fnmatch(str(file), pattern):
                        included.append(file)
            all_files = included
        
        # Apply exclude patterns (including defaults)
        exclude_patterns = (exclude_patterns or []) + self.default_excludes
        filtered_files = []
        for file in all_files:
            file_str = str(file)
            if not any(fnmatch.fnmatch(file_str, pattern) for pattern in exclude_patterns):
                filtered_files.append(file)
        
        # Limit files if specified
        if max_files:
            filtered_files = filtered_files[:max_files]
        
        print(f"\n[*] Scanning {len(filtered_files)} files...")
        print(f"[*] Include patterns: {include_patterns or 'all'}")
        print(f"[*] Exclude patterns: {len(exclude_patterns)} patterns")
        
        # Thread pool for parallel scanning
        with ThreadPoolExecutor(max_workers=min(8, len(filtered_files))) as executor:
            futures = {executor.submit(self.scan_file, f): f for f in filtered_files}
            
            for i, future in enumerate(as_completed(futures), 1):
                if i % 100 == 0 or i == len(filtered_files):
                    print(f"    Progress: {i}/{len(filtered_files)} files...")
                
                vulns = future.result()
                with self.lock:
                    self.vulnerabilities.extend(vulns)
        
        # Sort for deterministic output
        self.vulnerabilities.sort(key=lambda v: (v['file'], v['line'], v['type']))
        
        return self.vulnerabilities
    
    def generate_report(self, output_format: str = 'both', top_n: int = 10, group_by_file: bool = False):
        """Generate report with optional file grouping"""
        if not self.vulnerabilities:
            print("\nâœ… No vulnerabilities found!")
            return
        
        severity_groups = {}
        severity_order = ['CRITICAL', 'HIGH', 'MEDIUM', 'LOW']
        
        for vuln in self.vulnerabilities:
            sev = vuln['severity']
            if sev not in severity_groups:
                severity_groups[sev] = []
            severity_groups[sev].append(vuln)
        
        print("\n" + "="*60)
        print("SPR{K}3 VULNERABILITY SCAN REPORT v4.5")
        print("="*60)
        print(f"\nðŸ“Š Summary:")
        print(f"   Files scanned: {self.scan_count}")
        print(f"   Total vulnerabilities: {len(self.vulnerabilities)}")
        
        for severity in severity_order:
            if severity in severity_groups:
                count = len(severity_groups[severity])
                emoji = {'CRITICAL': 'ðŸš¨', 'HIGH': 'âš ï¸', 'MEDIUM': 'âš¡', 'LOW': 'â„¹ï¸'}.get(severity, '')
                print(f"   {emoji} {severity}: {count}")
        
        # Group by file if requested
        if group_by_file:
            self._report_by_file()
        else:
            self._report_by_severity(severity_groups, severity_order, top_n)
        
        if output_format in ['json', 'both']:
            self._save_json_report()
    
    def _report_by_file(self):
        """Report grouped by file"""
        by_file = {}
        for vuln in self.vulnerabilities:
            file = vuln['file']
            if file not in by_file:
                by_file[file] = []
            by_file[file].append(vuln)
        
        print("\nðŸ“ Vulnerabilities by File:")
        for file, vulns in sorted(by_file.items()):
            rel_path = file.replace(os.path.expanduser('~'), '~')
            print(f"\n  {rel_path} ({len(vulns)} issues):")
            
            for vuln in sorted(vulns, key=lambda v: v['line']):
                emoji = {'CRITICAL': 'ðŸš¨', 'HIGH': 'âš ï¸', 'MEDIUM': 'âš¡', 'LOW': 'â„¹ï¸'}.get(vuln['severity'], '')
                print(f"    Line {vuln['line']:4d} {emoji} [{vuln['severity']:8s}] {vuln['type']}")
                if vuln.get('fix_hint'):
                    print(f"              Fix: {vuln['fix_hint']}")
    
    def _report_by_severity(self, severity_groups, severity_order, top_n):
        """Traditional report by severity"""
        for severity in severity_order[:2]:  # CRITICAL and HIGH
            if severity in severity_groups:
                vulns = severity_groups[severity]
                emoji = 'ðŸš¨' if severity == 'CRITICAL' else 'âš ï¸'
                print(f"\n{emoji} {severity} Vulnerabilities (top {min(top_n, len(vulns))}):")
                
                by_type = {}
                for vuln in vulns:
                    if vuln['type'] not in by_type:
                        by_type[vuln['type']] = []
                    by_type[vuln['type']].append(vuln)
                
                shown = 0
                for vuln_type, type_vulns in sorted(by_type.items(), key=lambda x: -len(x[1])):
                    if shown >= top_n:
                        break
                    
                    print(f"\n   [{vuln_type}] - {len(type_vulns)} instances")
                    print(f"   {type_vulns[0]['description']}")
                    print(f"   Fix: {type_vulns[0]['fix_hint']}")
                    
                    for vuln in type_vulns[:3]:
                        rel_path = vuln['file'].replace(os.path.expanduser('~'), '~')
                        print(f"      Example: {rel_path}:{vuln['line']}")
                    
                    shown += len(type_vulns[:3])
    
    def _save_json_report(self):
        """Save JSON report with metadata"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        report_file = f"sprk3_scan_v45_{timestamp}.json"
        
        severity_counts = {}
        for vuln in self.vulnerabilities:
            sev = vuln['severity']
            severity_counts[sev] = severity_counts.get(sev, 0) + 1
        
        report_data = {
            'scan_metadata': {
                'scanner_version': 'SPR{K}3 v4.5',
                'scan_date': datetime.now().isoformat(),
                'files_scanned': self.scan_count,
                'total_vulnerabilities': len(self.vulnerabilities),
                'patterns_checked': len(self.patterns)
            },
            'summary': severity_counts,
            'vulnerabilities': self.vulnerabilities[:1000]  # Limit size
        }
        
        with open(report_file, 'w') as f:
            json.dump(report_data, f, indent=2)
        
        print(f"\nðŸ“ JSON report: {report_file}")
    
    def _to_sarif(self) -> dict:
        """Generate SARIF for CI/CD integration"""
        level_map = {"CRITICAL": "error", "HIGH": "error", "MEDIUM": "warning", "LOW": "note"}
        rules = {}
        results = []
        
        for v in self.vulnerabilities:
            rule_id = v["type"]
            if rule_id not in rules:
                rules[rule_id] = {
                    "id": rule_id,
                    "shortDescription": {"text": v["description"][:120]},
                    "fullDescription": {"text": v["description"]},
                    "help": {"text": f"{v.get('recommendation', '')}. Fix: {v.get('fix_hint', '')}"},
                    "properties": {"cwe": v.get("cwe", "N/A")}
                }
            
            results.append({
                "ruleId": rule_id,
                "level": level_map.get(v["severity"], "warning"),
                "message": {"text": f'{v["description"]} | Fix: {v.get("fix_hint", "")}'},
                "locations": [{
                    "physicalLocation": {
                        "artifactLocation": {"uri": v["file"]},
                        "region": {"startLine": v["line"]}
                    }
                }]
            })
        
        return {
            "version": "2.1.0",
            "$schema": "https://json.schemastore.org/sarif-2.1.0.json",
            "runs": [{
                "tool": {
                    "driver": {
                        "name": "SPR{K}3 v4.5",
                        "informationUri": "https://github.com/SPR-k-3/SPRk-3-platform",
                        "rules": list(rules.values())
                    }
                },
                "results": results
            }]
        }

def main():
    import argparse
    
    print("\n" + "="*60)
    print("  SPR{K}3 Vulnerability Scanner v4.5 - Platform Edition")
    print("  30+ patterns | Notebook support | Taint analysis")
    print("  Enterprise ML/AI Security")
    print("="*60)
    
    parser = argparse.ArgumentParser(description='Platform-grade ML/AI security scanner')
    parser.add_argument('path', help='Directory or file to scan')
    parser.add_argument('--include', nargs='+', help='Include patterns (glob)')
    parser.add_argument('--exclude', nargs='+', help='Exclude patterns (glob)')
    parser.add_argument('--format', choices=['console', 'json', 'both'], default='both')
    parser.add_argument('--top', type=int, default=10, help='Top vulnerabilities to show')
    parser.add_argument('--max-files', type=int, help='Maximum files to scan')
    parser.add_argument('--fail-on', choices=['CRITICAL','HIGH','MEDIUM','LOW','NONE'], default='HIGH')
    parser.add_argument('--group-by-file', action='store_true', help='Group output by file')
    parser.add_argument('--sarif', action='store_true', help='Generate SARIF output')
    parser.add_argument('--baseline', help='Baseline file for suppressions')
    parser.add_argument('--write-baseline', action='store_true', help='Write baseline and exit')
    
    args = parser.parse_args()
    
    scanner = SPRk3VulnerabilityScanner()
    
    if os.path.isfile(args.path):
        vulns = scanner.scan_file(Path(args.path))
        scanner.vulnerabilities = vulns
    else:
        scanner.scan_directory(
            args.path,
            include_patterns=args.include,
            exclude_patterns=args.exclude,
            max_files=args.max_files
        )
    
    # Apply baseline
    baseline = scanner._load_baseline(args.baseline)
    if baseline:
        original_count = len(scanner.vulnerabilities)
        scanner.vulnerabilities = [v for v in scanner.vulnerabilities
                                   if (v["file"], v["line"], v["type"]) not in baseline]
        print(f"\n[*] Baseline: Suppressed {original_count - len(scanner.vulnerabilities)} findings")
    
    # Write baseline
    if args.write_baseline:
        baseline_data = [{"file": v["file"], "line": v["line"], "type": v["type"]}
                        for v in scanner.vulnerabilities]
        with open('baseline.json', 'w') as f:
            json.dump(baseline_data, f, indent=2)
        print("\nðŸ“„ Wrote baseline.json")
        sys.exit(0)
    
    scanner.generate_report(
        output_format=args.format,
        top_n=args.top,
        group_by_file=args.group_by_file
    )
    
    # Generate SARIF
    if args.sarif:
        sarif = scanner._to_sarif()
        with open("sprk3_v45.sarif", "w") as f:
            json.dump(sarif, f, indent=2)
        print("ðŸ—‚  SARIF: sprk3_v45.sarif")
    
    # Exit code
    if scanner.vulnerabilities and args.fail_on != 'NONE':
        order = ['CRITICAL', 'HIGH', 'MEDIUM', 'LOW']
        threshold_idx = order.index(args.fail_on)
        
        for vuln in scanner.vulnerabilities:
            if order.index(vuln['severity']) <= threshold_idx:
                sys.exit(1)
    
    sys.exit(0)

if __name__ == "__main__":
    main()
